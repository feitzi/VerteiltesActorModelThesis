\chapter{Verteilte Systeme}\label{cha:distributedSystems}
Mit dem Beginn des Computerzeitalters in den 50er Jahren galten Leistungsstarke Rechner als kostenintensiv, benötigten viel Platz und operierten meist unabhängig und autark von anderen Geräten. Durch die Weiterentwicklung von Hardware sowie auch Software konnte im lauf der Zeit diese Entwicklung von Geräten so weit gebracht werden, dass heute Computer kostengünstig sowie platzsparend sind. Weiters ist die Entwicklung der Netzwerktechnologien so weit fortgeschritten, dass eine vernetzung der Geräte keine all zu große Herausforderung mehr ist. Die Geräte jedoch optimal miteinander kommunizieren zu lassen stellt Entwickler von verteilten Systemen immer wieder vor neuen Herausforderungen. \citep{tanenbaum2007distributed} \\
Dieses Kapitel soll eine Zusammenfassung über Verteile Systeme geben und dessen Problematiken aufzeigen sowie  bekannte Lösungsvorschläge erarbeiten.

\section{Definition Verteilte Systeme}\label{sec:distributedSystems:definition}
Der Begriff \textit{Verteilte Systeme} fasst eine große Anzahl an Themenblöcken zusammen, dementsprechend gibt es auch eine Mehrzahl an verschiedenen Definitionen welche sich zum Teil auch voneinander grob unterscheiden. Eine weitläufige und angesehene Definition ist jene von \cite{tanenbaum2007distributed}:
\begin{quote}
    Ein verteiltes System ist eine Ansammlung von eigenständigen Rechnern, die den Anwendern als ein einziges kohärentes System erscheint.
    \label{quote:distributedSystem:tanenbaum}
\end{quote}
In dieser Definition legt \cite{tanenbaum2007distributed} den Schwerpunkt auf die Beteiligten Komponenten, welche die Computer sowie die Benutzer sind. Die beteiligten Rechner arbeiten unabhängig voneinander in einem Verbund. Benutzer des Systems sehen jedoch die vernetzen Rechner nicht und müssen auch nichts darüber wissen, für den Benutzer erscheint das verteilte System als ein einzelnes zusammenhängedes System. Dadurch spürt der Benutzer zuerst keinen Unterschied, ob er mit einem einzelnen Rechner, einem Mainframe oder eben mit einem verteilten System interagiert \citep{tanenbaum2007distributed}. \\

\section{Ziele eines Verteilen Systems}\label{sec:distributedSystems:goales}
Verteilte Systeme bieten viele Vorteile und sind in einigen Bereichen von bedeutender Wichtigkeit. Jedoch ist der Einsatz eines verteilten Systems mit hohem Aufwand verbunden, weshalb nicht alle Probleme damit gelöst werden können. In \cite{tanenbaum2007distributed} werden die Ziele welche ein Verteiltes System verfolgt erläutert. Bei der Entscheidung ob ein Verteiltes System zur bewerkstelligung eines Problems beiträgt, sollte das zu lösende Problem mit den folgende Zielen vereinbar sein.

\subsection{Zuverfügungstellen von Ressourcen}\label{sec:distributedSystems:goales:resourceAccess} Das Hauptziel eines jeden Verteilten Systems ist es laut \cite{tanenbaum2007distributed} Ressourcen zu Verfügung zu stellen. Welche Art von Ressource ist unerheblich. Es kann sich um typische Web Ressourcen wie Files oder Texte handeln, oder auch physikalische Ressourcen wie beispielsweise Drucker, Scanner oder Fahrzeuge handeln.\\
Dies kann erforderlich sein um aus kostengründen, teure Ressourcen, einer möglichst breiten Maße an Benutzern zu verfügung zu stellen. Weiters kann der gemeinsame Zugriff auf eine oder mehrere Ressourcen zu einer besseren zusammenarbeit zwischen verteilten Teams führen. Durch die Weltweiter vernetzung durch das Internet bekommt die Vernetzung von verteilten Teams eine große Bedeutung zu. 
\subsection{Transperenz der Verteilung}\label{sec:distributedSystems:goales:Transperency} Wie schon aus der Definition aus Abschnitt \ref{sec:distributedSystems:definition} hervorgeht, ist ein primäres Ziel eines verteilen Systems die Transparenz des internen Aufbaues. Um transparenz gewährleisten zu können  müssen laut \cite{iec1995open} sowie \cite{tanenbaum2007distributed} folgende Punkte in einem verteilten System erfüllt sein:
\begin{description}
    \item[Transparenter Zugang] Es ist nicht relevant wie auf eine Ressource zugegriffen gibt. Bei differenzierten Zugriffsarten ist das Ergebnisse sowie die Möglichkeiten der Verarbeitung der Ressource die selbe. 
    \item[Orsunabhängig] Eine laut \cite{tanenbaum2007distributed} bedeutende Eigenschaft der Transparenz in einem Verteilten System ist der Ortsunabhängige zugriff auf eine Ressource. Der Benutzer muss nicht den physikalischen Ort einer Ressource wissen um darauf zugreifen zu können. 
    \item[Migration] Wird eine bereits im System befindliche Ressource an einen neuen Ort verschoben, so ist diese weiterhin über die gleiche Adresse wie zuvor erreichbar.
    \item [Standortwechsel] Eine Ressource welche von einem Benutzer gerade in Verwendung ist und physikalisch an einen neuen Ort Migriert wird, ist ohne Unterbrechung weiterhin für den Benutzer verwendbar.
    \item[Replizierung] Wird eine einzelne Ressource repliziert, bekommt der Verwender von dieser Replizierung nichts mit und kann diese so verwenden wie wenn die Replizierung nicht vorhanden ist. 
    \item[Gleichzeitiger Zugriff] Eine Ressource kann unter umständen auch von mehreren Benutzern gleichzeitig verwendet werden. Dieser zugriff von mehreren unterschiedlichen Benutzern ist für den einzelnen Benutzern nicht spürbar,
    \item[Fehlerresistent] Tritt bei einer Ressource ein Fehler auf, wird dieser vom User verborgen behoben oder eine andere Maßnahme ergriffen welche dem Benutzer, so gut wie möglich, ein ungehindertes Weiterarbeiten ermöglicht.
\end{description}
Eine weitere Definition von \textit{Leslie Lampert} besagt, dass ein Benutzer erst merkt mit einem Verteilten System zu arbeiten, wenn ein Rechner, von dessen existenz er bisher nichts wusste, nicht mehr funktioniert und unmittelbar Auswirkung auf seine Arbeit hat am System hat \citep{Schroeder:1993}. Die Definition von Lampert zeigt nochmals die Bedeutung Transparenz für ein verteiltes System. \\
Jedoch ist in praktischen Beispielen eine volle Transparenz eines Verteilten Systems nicht immer optimal. Wie in \cite{tanenbaum2007distributed} beschrieben sind beispielsweise transparente Zeitunterschiede in verteilten Systemen nicht immer für den Benutzer optimal. Deshalb ist eine sinnolle Abwägung von Transparenz bestimmter Bestandteile des Systems gegenüber dem konkreten Anwendungsfall vorzunehmen. 

\subsection{Offenheit}\label{sec:distributedSystems:goales:openness} 
Ein Verteiltes System besteht in der Regel aus verschiedensten Komponenten welche unterscheider sowie mit externen Teilnehmer kommunizieren. Um eine solche Kommunikation zu ermöglichen müssen Verteilte Systeme Schnittstelldefinitionen offen und standardisiert anbieten. Weiters ist es notwendig das ein Verteiltes System erweiterbar ist, sprich neue Komponenten während des Betriebes hinzugefügt werden können. Auch wenn neue Komponenten gänzlich andere Eigenschaften haben, wie beispielsweise Betriebsystem, Hardware etc..., so ist es möglich wenn sich alle beteiligen Komponenten an die definierten Schnittstellen halten. Durch diese Vorgehensweise ist ein System offen.  

\subsection{Skalierung}\label{sec:distributedSystems:goales:scalability} 
Das vierte Ziel eines Verteilten Systems ist die Möglichkeit sich auf veränderte Rahmenbedingungen einzustellen. Skalierung in einem Computersystem kann laut \cite{Neuman1993Scale} in drei Dimmensionen unterteilt werden. Diese sind wie folgt: 
\begin{description}
    \item[Numerisch] Die erste Dimmension zielt auf die Anzahl an Beteiligten Ressourcen sowie Benutzern ab. Diese variiert kann in einem verteilen System stark variieren.
    \item[Geografisch] Die geografische Dimension betrachtet bei der Skalierung die geografischen Distanzen zwischen den beteiligten Komponenten. Dabei entsteht für den Benutzer kein Nachteil wenn eine Komponenten hinzugefügt wird, welche sich geografisch weit weg befindet.
    \item[Administrativ] In einem verteilen System können mehrere Organisationen beteiligt sein. Die Administrative Dimmension bei der Skalierung zeigt die Beteiligten Organisationen welche das System betreiben auf.
\end{description}
Ein System ist demnach laut \cite{Neuman1993Scale} skalierbar wenn der Anstieg an Benutzern und Ressourcen bewältigt werden kann, ohne das Administrationsaufwand sowie Performance darunter benachteiligt wird. \\

\subsubsection{Probleme der Skalierung}
Das skalieren eines Systems stellt Entwickler vor immense Hürden. Ein häufiges Problem sind laut \cite{tanenbaum2007distributed} einzelne Komponenten, welche nicht skalierbar sein. Steigt nun die Anzahl an Zugriffen auf diese Komponente, kann dies zu einem Flaschenhals für das gesamte System werden. Jedoch sind unter bestimmten Umständen, solche zentralisierten Komponenten nicht verhinderbar. Deshalb sollten laut \cite{tanenbaum2007distributed} diese zentralisierten Teile so gut wie möglich vom Rest des Systems entkoppelt sein. Generell sind in \cite{tanenbaum2007distributed} folgende vier Regeln angegeben, welche ein Ablauf innerhalb eines skalierbaren, verteilen Systems erfüllen muss:
\begin{enumerate}
    \item Keine Komponente hat einen kompletten Überblick über das System
    \item Entscheidungen innerhalb einer Komponente werden nur aufgrund lokalen Informationen getroffen
    \item Ein Fehler einer einzelnen Komponente lässt den Ablauf nicht fehlschalgen
    \item Keine Entscheidung fällt aufgrund der Basis das es eine synchronisierte Zeit gibt
\end{enumerate}
Der vierte und letzte Punkt, ist laut \cite{tanenbaum2007distributed} deshalb nötig, weil es in einer verteilten Umgebung technisch unmöglich ist, eine Zeit exakt zu synchronisieren. Dieses Problem wird in \cite{lamport1978time} näher erläutert.\\
Skalierung eines Systems ist eine große Herausforderung und benötigt ein passendes, auf den Anwendungsfall angepasstes Konzept. In einem verteiltem System ist Skalierung jedoch ein äußert wichtiges Prinzip. \cite{tanenbaum2007distributed}
 
\section{Limitierungen in Verteilten Systeme}
Verteilte Systeme sind aufgrund Ihrer komplexität dementsprechend schwer umzusetzen. Bei der Realisierung eines Systeme sind dementsprechend auch einige generell gültige Limitierungen zu berücksichtigen. Dazu gehören unter anderem die von Deutsch definierten inkorrekten Annahmen in einem verteilen System sowie das \textit{CAP-Theorem} von Brewer, welche beide Nachfolgend betrachtet werden.

\subsection{Die acht falschen Annhamen einer Verteilten Anwendung}\label{sec:distributedSystems:wrongAssumptions} 
Durch die komplexität eines verteilten Systems kommt es, auch durch erfahrene Entwickler, immer wieder zu falschen Annahmen während der Konzeptionsphase. Die häufigsten fehlerhaften Annahmen wurden in \cite{deutsch1994eight} zusammengefasst. Diese Liste an fehlerhaften Grundsatzregeln sollten bei der Entwicklung eines verteilen Systems beachtet werden. Nachfolgend eine Übersicht über die acht Punkten von \cite{deutsch1994eight} welche in \cite{rotem2006fallacies} genauer beschrieben werden.
\begin{description}
    \item[Das Netzwerk ist ausfallsicher]
    Das verwenden eines Netzwerkes, unabhängig von der Ausführung dieses, kann immer zu Fehlern führen. Ein Netzwerk besteht laut \cite{rotem2006fallacies} immer aus Komponenten bei welchen plötzliche Störungen auftretten können. Daraus lässt sich folgend ableitend, dass bei der Entwicklung eines Systems nie darauf vertraut werden kann, dass Komponenten, welche über ein Netzwerk angebunden sind, auch tatsächlich erreicht werden können. In Muster aus Abschnitt \ref{sec:actor:patterns:guaranteedDelivery} wird dies beispielsweise bereits beachtet.
    \item[Das Netzwerk ist sicher]
    Informationen welche über Netzwerke versendet werden, sind Grundsätzlich nicht davor gesichert, von unbefugten gelesen zu werden. Der verwender des Netzwerkes muss sich deshalb selbst um die Sicherheit der Daten kümmern.
    \item[Das Netzwerk ist homogen]
    Die Bestandteile eines Netzwerkes unterscheiden sich umso mehr, umso größer das Netzwerk ist. Selbst kleine Netzwerke beinhalteten meist größere Unterschiede wie beispielsweise verschiedene Betriebsystem der Teilnehmer. Netzwerke sind deshalb nicht homogen, weshalb die Verwendung von standardisierten Protokollen wie beispielsweise \textit{IP} oder \textit{XML} ratsam ist. Die nicht homogenität eines Netzwerkes führt laut \cite{rotem2006fallacies} meist dann zu Problemen wenn auf Proprietäre Protokolle zurückgegriffen wird.
    \item[Die Netzwerktopologie ändert sich nicht]
    Die verwendete Netzwerkinfrastruktur sowie deren Konfiguration ist laut \cite{rotem2006fallacies} nur auf den ersten blick beständig. In einem Testszenario liegt meist die Konfiguration und der Aufbau der Infrastruktur in den Händen des Entwicklerteams. In Produktionsumgebung liegt überliegt dies jedoch meist fremden Netzwerkadministratoren welche änderungen im Netzwerk vornehmen welche für die Entwickler der Anwendung nicht vorhersehbar sind. Das bedeutet das Entwickler einer verteilten Anwendung diese so Umsetzen, das sie mögliche änderungen des Netzwerkes unterstützen.  Beispiele hierführ sind neue Routingstrecken, andere Netzwerkadressen oder der wechsel von Netzwerkressourcen. 
    \item[Die Latenz ist null]
    Die Zeitdauer welche vergeht bis ein Datenpaket in einem Netzwerk übertagen wird, nennt sich Latenz. Die Latenz ist aufgrund physikalischer Gesetze niemals null. Sie variiert jedoch stark, je nach dem welches Übertragungsmedium verwendet wird und welche Strecke überwunden werden soll. Eine häufige  Fehlerquellen ist \cite{rotem2006fallacies}, dass Tests und Probeläufe für ein verteiltes System unter optimale Netzwerkbedingungen durchgeführt werden, wo die Latenz gering ist. In der Produktionsumgebung steigt jedoch dann aufgrund unterschiedlicher Faktoren die Latenz, was in weiterer folge dazu führt das die Anwendung in einen Fehlerzustand resultiert. 
    \item[Der Datendurchsatz ist unendlich]
    Im Gegensatz zur Latenz wird beim Datendurchsatz gemessen wie viele Daten gleichzeitig übertragen werden können. Diese ist in Netzwerken ebenfalls stark begrenzt. Jedoch hat sich dieser Faktor in modernen Netzwerken laut \cite{rotem2006fallacies} stark verbessert. Trotzdem ist der Datendurchsatz nicht unendlich und eine Verteile Anwendung muss darauf achten welche Datenmengen übertragen werden.  
    \item[Keine Kosten bei der Datenübertragung]
    Keine Kosten bezieht sich hier einerseits auf die technischen Kosten als auch finanziele Kosten. Auf technischer Seite kostet es Ressourcen Daten in ein Netzwerk einbringen und diese auch wieder auszulesen. So werden unter anderem Ressourcen verbraucht die Daten zu serialisieren sowie die Verbindung zum Netzwerk aufzubauen und auch zu halten. Weiters benötigt die Erstellung sowie die Erhaltung eines Netwerkes finanziele Ressourcen welche je nach größe des Netzwerkes beachtlich sein können \cite{rotem2006fallacies}.
    \item[Es gibt nur einen Administrator]
    Wird eine Anwendung in einer größeren Umgebung ausgerollt, so sind auch mehr Personen daran beteiligt. Auch die Administration eines Netzwerkes kann dann unterschiedlichen Personen obliegen. Vorallem wenn die Umgebung in welchem die Anwendung läuft zwischen mehreren Organisationen aufgeteilt ist. Meist sind diese Personen auch nicht an der Entwicklung der Anwendung beteiligt. Deshalb ist es erforderlich Verwaltungstools oder ähnliches für diese Gruppe an Netzwerkadministratoren anzubieten damit diese einen überblick über die Anwendung bekommen \cite{rotem2006fallacies}.  
\end{description}
Diese acht Annahmen sind trotz ihres Alters auch heute noch wichtig und sollten von Architekten für verteilte Systeme immer wieder beachtet werden. Auch wenn die Regeln meist logisch und klar erscheinen werden sie immer wieder aufgrund unterschiedlichster Gründe gebrochen. \cite{rotem2006fallacies} 

\section{CAP-Theorem}\label{sec:distributedSystems:capTheorem}
Eine weitere bedeutende Limitierung innerhalb eines verteilten System stellt das \textit{CAP-Theorem}  dar. Das von Eric Brewer in \cite{Brewer2000TowardsSystems}  erstmals beschriebene Theorem beschreibt die Limitierung von drei gewünschten Eigenschaften in einem verteilen System. Diese drei Eigenschaften sind Konsistenz, Verfügbarkeit sowie Partition Toleranz. Nach dem \textit{CAP-Theorem} können in jedem System nur zwei der drei Eigenschaften garantiert werden. Auf eine der drei Eigenschaften muss auf jeden Fall verzichtet werden. In \cite{gilbertPerspectiveCAPTheorem2012} wird das \textit{CAP-Theorem} mit dem aktuellen Stand der Dinge wie folgt beschrieben.

\begin{description}
\item[Konsistenz]
Die Konsistenz der Daten welche ein verteiltes System als Antwort an Anfragen gibt sollte gegeben sein. Das ist je nach Komplexitätsgrad der Anwendung unterschiedlich möglich. So sind laut \cite{gilbertPerspectiveCAPTheorem2012} der Koordinationsaufwand für die erhaltung der Daten ausschlaggebend für die erhaltung der Konsistenz eines Systems. Können die Daten aufgrund von statischen Berechnungen erzeugt werden ist die Konsistenz wesentlich leichter zu realisieren, als wenn die Daten über das gesamte Netzwerk verteilt werden müssen. Ein verteiltes System ist dann Konsistenz, wenn sichergestellt ist, dass jede beteiligte Komponente den gleichen Datenbestand sehen kann und somit keine inkonsistentem entstehen können.   

\item[Verfügbarkeit]
Die Verfügbarkeit eines Systems, wie bereits im {\textit{Reactive Manifesto}} in Kapitel \ref{reactivo:responsive} gefordert, bedeutet, dass das System zu jeder Zeit auf ankommende Anfragen beantworten kann. Die Antwort muss dabei innerhalb einer, zum Kontext der Aufgabe vertretbaren Zeit, erfolgen.

\item[Partition Toleranz]
Da das verteilte System aus mehreren beteiligten Komponenten besteht, müssen diese auch miteinander kommunizieren. Da, wie bereits in Abschnitt \ref{sec:distributedSystems:wrongAssumptions} besprochen, die Kommunikation in einem System nie garantiert werden kann, können durch Verbindungsunterbrechungen im Netzwerk Partitionen entstehen. Partitioniert sich ein Netzwerk, ist die Kommunikation zwischen den entstandenen Partitionen temporär nicht mehr möglich.
\end{description}
Eie Regel, das in einem verteilten System eben nur zwei der drei genannten Kriterien gleichzeitig gewährleistet werden kann, führt dazu, dass man sich, abwiegend auf basis des Anwendungsfall, von einer der drei Eigenschaften trennen muss. Dies kann jedoch oft durch organisatorische Prozesse abgedeckt werden, was jedoch nichts mit dem \textit{CAP-Theorem} zu tun hat. Bei einem Ausfallsicheren verteilten System ist Partition Toleranz auf jeden Fall voraussetzung. Jedoch ist auch hier wieder die optimale Zusammensetzung von der konkreten umzusetzenden Thematik abhängig. Um beispielsweise einen kompromiss mit der Konsistenz der Daten zu erhalten bietet sich das in Kapitel \ref{sec:transactionTheory:base} beschriebene \textit{BASE-Prinzip} an.